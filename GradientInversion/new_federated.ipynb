{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from aijack.attack import GAN_Attack\n",
    "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
    "from aijack.utils import NumpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def prepare_dataloaders():\n",
    "    at_t_dataset_train = torchvision.datasets.MNIST(\n",
    "        root=\"./\", train=True, download=True\n",
    "    )\n",
    "    at_t_dataset_test = torchvision.datasets.MNIST(\n",
    "        root=\"./\", train=False, download=True\n",
    "    )\n",
    "\n",
    "    X = at_t_dataset_train.data.numpy()\n",
    "    y = at_t_dataset_train.targets.numpy()\n",
    "\n",
    "    # ToTensor：画像のグレースケール化（RGBの0~255を0~1の範囲に正規化）、Normalize：Z値化（RGBの平均と標準偏差を0.5で決め打ちして正規化）\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "    )\n",
    "\n",
    "    # idx_1 = random.sample(range(400), 200)\n",
    "    # idx_2 = list(set(range(400)) - set(idx_1))\n",
    "    idx_1 = np.where(y < 5)[0]\n",
    "    idx_2 = np.where(y >= 5)[0]\n",
    "\n",
    "    global_trainset = NumpyDataset(\n",
    "        at_t_dataset_test.data.numpy(),\n",
    "        at_t_dataset_test.targets.numpy(),\n",
    "        transform=transform,\n",
    "    )\n",
    "    global_trainloader = torch.utils.data.DataLoader(\n",
    "        global_trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    trainset_1 = NumpyDataset(X[idx_1], y[idx_1], transform=transform)\n",
    "    trainloader_1 = torch.utils.data.DataLoader(\n",
    "        trainset_1, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    trainset_2 = NumpyDataset(X[idx_2], y[idx_2], transform=transform)\n",
    "    trainloader_2 = torch.utils.data.DataLoader(\n",
    "        trainset_2, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    return X, y, [trainloader_1, trainloader_2], global_trainloader, [200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "X, y, trainloaders, global_trainloader, dataset_nums = prepare_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
    "\n",
    "shape_img = (28, 28)\n",
    "num_classes = 10\n",
    "channel = 1\n",
    "hidden = 588\n",
    "\n",
    "net_1 = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "net_2 = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "global_model = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "\n",
    "clients = [FedAvgClient(net_1, user_id=0), FedAvgClient(net_2, user_id=1)]\n",
    "optimizers = [optim.SGD(clients[0].parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9), optim.SGD(clients[1].parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9)]\n",
    "server = FedAvgServer(clients, global_model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "        server.parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     print(epoch)\n",
    "#     for client, local_trainloader, local_optimizer in zip(clients, trainloaders, optimizers):\n",
    "#         for data in local_trainloader:\n",
    "#             inputs, labels = data\n",
    "#             local_optimizer.zero_grad()\n",
    "#             outputs = client(inputs)\n",
    "#             loss = criterion(outputs, labels.to(torch.int64))\n",
    "#             client.backward(loss)\n",
    "#             optimizer.step()\n",
    "#             print(loss)\n",
    "#     server.action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10: 71.49229431152344, (best_iter=10: 71.49229431152344)\n",
      "iter=20: 70.78050231933594, (best_iter=20: 70.78050231933594)\n",
      "iter=30: 70.54597473144531, (best_iter=30: 70.54597473144531)\n",
      "iter=40: 70.5264892578125, (best_iter=40: 70.5264892578125)\n",
      "iter=50: 70.52376556396484, (best_iter=50: 70.52376556396484)\n",
      "iter=60: 70.52336883544922, (best_iter=60: 70.52336883544922)\n",
      "iter=70: 70.52311706542969, (best_iter=70: 70.52311706542969)\n",
      "iter=80: 70.52298736572266, (best_iter=80: 70.52298736572266)\n",
      "iter=90: 70.52283477783203, (best_iter=89: 70.5228271484375)\n",
      "iter=100: 70.52275085449219, (best_iter=98: 70.52275085449219)\n",
      "iter=110: 70.52272033691406, (best_iter=106: 70.52272033691406)\n",
      "iter=120: 70.5226821899414, (best_iter=113: 70.5226821899414)\n",
      "iter=130: 70.52265930175781, (best_iter=129: 70.52265930175781)\n",
      "iter=140: 70.52265930175781, (best_iter=133: 70.52265167236328)\n",
      "iter=150: 70.52264404296875, (best_iter=143: 70.52264404296875)\n",
      "iter=160: 70.52262878417969, (best_iter=159: 70.52261352539062)\n",
      "iter=170: 70.52261352539062, (best_iter=166: 70.5226058959961)\n",
      "iter=180: 70.52262115478516, (best_iter=166: 70.5226058959961)\n",
      "iter=190: 70.52261352539062, (best_iter=188: 70.52259826660156)\n",
      "iter=200: 70.5226058959961, (best_iter=188: 70.52259826660156)\n",
      "iter=210: 70.52259826660156, (best_iter=204: 70.52259063720703)\n",
      "iter=220: 70.5226058959961, (best_iter=204: 70.52259063720703)\n",
      "iter=230: 70.52261352539062, (best_iter=204: 70.52259063720703)\n",
      "iter=240: 70.5226058959961, (best_iter=204: 70.52259063720703)\n",
      "iter=250: 70.52262115478516, (best_iter=204: 70.52259063720703)\n",
      "iter=255: loss did not improve in the last 50 rounds.\n"
     ]
    }
   ],
   "source": [
    "from aijack.attack import GradientInversion_Attack, GradientInversionAttackManager\n",
    "\n",
    "# # DLG Attack (Zhu, Ligeng, Zhijian Liu, and Song Han. \"Deep leakage from gradients.\" Advances in Neural Information Processing Systems 32 (2019).)\n",
    "# dlg_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\")\n",
    "# FedAvgServer_DLG = dlg_manager.attach(FedAvgServer)\n",
    "\n",
    "# # GS Attack (Geiping, Jonas, et al. \"Inverting gradients-how easy is it to break privacy in federated learning?.\" Advances in Neural Information Processing Systems 33 (2020): 16937-16947.)\n",
    "# gs_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"cossim\", tv_reg_coef=0.01)\n",
    "# FedAvgServer_GS = gs_manager.attach(FedAvgServer)\n",
    "\n",
    "# iDLG (Zhao, Bo, Konda Reddy Mopuri, and Hakan Bilen. \"idlg: Improved deep leakage from gradients.\" arXiv preprint arXiv:2001.02610 (2020).)\n",
    "idlg_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\", num_iteration=1000, optimize_label=False)\n",
    "FedAvgServer_iDLG = idlg_manager.attach(FedAvgServer)\n",
    "\n",
    "# # CPL (Wei, Wenqi, et al. \"A framework for evaluating gradient leakage attacks in federated learning.\" arXiv preprint arXiv:2004.10397 (2020).)\n",
    "# cpl_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\", optimize_label=False, lm_reg_coef=0.01)\n",
    "# FedAvgServer_CPL = cpl_manager.attach(FedAvgServer)\n",
    "\n",
    "# # GradInversion (Yin, Hongxu, et al. \"See through gradients: Image batch recovery via gradinversion.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.)\n",
    "# gi_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\", optimize_label=False, bn_reg_layers=[global_model.body[1], global_model.body[4], global_model.body[7]],\n",
    "#                                     group_num = 5, tv_reg_coef=0.00, l2_reg_coef=0.0001, bn_reg_coef=0.001, gc_reg_coef=0.001)\n",
    "# FedAvgServer_GI = gi_manager.attach(FedAvgServer)\n",
    "\n",
    "server = FedAvgServer_iDLG(clients, global_model, lr=0.02)\n",
    "# --- normal federated learning --- #\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "        server.parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "for client, local_trainloader, local_optimizer in zip(clients, trainloaders, optimizers):\n",
    "    for data in local_trainloader:\n",
    "        inputs, labels = data\n",
    "        local_optimizer.zero_grad()\n",
    "        outputs = client(inputs)\n",
    "        loss = criterion(outputs, labels.to(torch.int64))\n",
    "        client.backward(loss)\n",
    "        optimizer.step()\n",
    "    \n",
    "server.action()\n",
    "reconstructed_image, reconstructed_label = server.attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.imshow(reconstructed_image.detach().numpy()[0][0], cmap=\"gray\")\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title(reconstructed_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3afb210fe50ad1836e9c960d622d1338248a5c454d742c389c06a20b52875194"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
