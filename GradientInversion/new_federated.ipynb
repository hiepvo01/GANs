{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\FederatedLearningTensorflow\\.venv\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: [WinError 126] The specified module could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from aijack.attack import GAN_Attack\n",
    "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
    "from aijack.utils import NumpyDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "    \n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, channel=3, hideen=768, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        act = nn.Sigmoid\n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(channel, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "            nn.Conv2d(12, 12, kernel_size=5, padding=5 // 2, stride=1),\n",
    "            nn.BatchNorm2d(12),\n",
    "            act(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hideen, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.body(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def prepare_dataloaders():\n",
    "    at_t_dataset_train = torchvision.datasets.MNIST(\n",
    "        root=\"./\", train=True, download=True\n",
    "    )\n",
    "    at_t_dataset_test = torchvision.datasets.MNIST(\n",
    "        root=\"./\", train=False, download=True\n",
    "    )\n",
    "\n",
    "    X = at_t_dataset_train.data.numpy()\n",
    "    y = at_t_dataset_train.targets.numpy()\n",
    "\n",
    "    # ToTensor：画像のグレースケール化（RGBの0~255を0~1の範囲に正規化）、Normalize：Z値化（RGBの平均と標準偏差を0.5で決め打ちして正規化）\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "    )\n",
    "\n",
    "    # idx_1 = random.sample(range(400), 200)\n",
    "    # idx_2 = list(set(range(400)) - set(idx_1))\n",
    "    idx_1 = np.where(y < 5)[0]\n",
    "    idx_2 = np.where(y >= 5)[0]\n",
    "\n",
    "    global_trainset = NumpyDataset(\n",
    "        at_t_dataset_test.data.numpy(),\n",
    "        at_t_dataset_test.targets.numpy(),\n",
    "        transform=transform,\n",
    "    )\n",
    "    global_trainloader = torch.utils.data.DataLoader(\n",
    "        global_trainset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    trainset_1 = NumpyDataset(X[idx_1], y[idx_1], transform=transform)\n",
    "    trainloader_1 = torch.utils.data.DataLoader(\n",
    "        trainset_1, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    trainset_2 = NumpyDataset(X[idx_2], y[idx_2], transform=transform)\n",
    "    trainloader_2 = torch.utils.data.DataLoader(\n",
    "        trainset_2, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    return X, y, [trainloader_1, trainloader_2], global_trainloader, [200, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "X, y, trainloaders, global_trainloader, dataset_nums = prepare_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aijack.collaborative import FedAvgClient, FedAvgServer\n",
    "\n",
    "shape_img = (28, 28)\n",
    "num_classes = 10\n",
    "channel = 1\n",
    "hidden = 588\n",
    "\n",
    "net_1 = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "net_2 = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "client1 = FedAvgClient(net_1, user_id=0)\n",
    "client2 = FedAvgClient(net_1, user_id=0)\n",
    "global_model = LeNet(channel=channel, hideen=hidden, num_classes=num_classes)\n",
    "client1.to(device)\n",
    "client2.to(device)\n",
    "global_model.to(device)\n",
    "\n",
    "clients = [client1, client2]\n",
    "optimizers = [optim.SGD(clients[0].parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9), optim.SGD(clients[1].parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9)]\n",
    "server = FedAvgServer(clients, global_model)\n",
    "server.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "        server.parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "# for epoch in range(3):\n",
    "#     print(epoch)\n",
    "#     for client, local_trainloader, local_optimizer in zip(clients, trainloaders, optimizers):\n",
    "#         for data in local_trainloader:\n",
    "#             inputs, labels = data\n",
    "#             local_optimizer.zero_grad()\n",
    "#             outputs = client(inputs)\n",
    "#             loss = criterion(outputs, labels.to(torch.int64))\n",
    "#             client.backward(loss)\n",
    "#             optimizer.step()\n",
    "#             print(loss)\n",
    "#     server.action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "epoch 0: client-1 5.306504619746891\n",
      "epoch 0: client-2 4.857981383304427\n",
      "epoch 0: accuracy is  0.27\n",
      "iter=10: 97849.8828125, (best_iter=7: 97378.15625)\n",
      "iter=20: 97849.8828125, (best_iter=7: 97378.15625)\n",
      "iter=30: 97849.8828125, (best_iter=7: 97378.15625)\n",
      "iter=40: 97849.8828125, (best_iter=7: 97378.15625)\n",
      "iter=50: 97849.8828125, (best_iter=7: 97378.15625)\n",
      "iter=58: loss did not improve in the last 50 rounds.\n",
      "epoch 1: client-1 3.722973164476137\n",
      "epoch 1: client-2 4.077553586041359\n",
      "epoch 1: accuracy is  0.2681\n",
      "iter=10: 65736.3359375, (best_iter=10: 65736.3359375)\n",
      "iter=20: 65452.26171875, (best_iter=20: 65452.26171875)\n",
      "iter=30: 65303.75390625, (best_iter=30: 65303.75390625)\n",
      "iter=40: 65201.3515625, (best_iter=40: 65201.3515625)\n",
      "iter=50: 65143.09765625, (best_iter=50: 65143.09765625)\n",
      "iter=60: 65138.484375, (best_iter=52: 65138.48046875)\n",
      "iter=70: 65138.484375, (best_iter=52: 65138.48046875)\n",
      "iter=80: 65138.48046875, (best_iter=52: 65138.48046875)\n",
      "iter=90: 65138.484375, (best_iter=52: 65138.48046875)\n",
      "iter=100: 65138.48046875, (best_iter=52: 65138.48046875)\n",
      "iter=103: loss did not improve in the last 50 rounds.\n",
      "epoch 2: client-1 3.7224543169068762\n",
      "epoch 2: client-2 3.9796286614795933\n",
      "epoch 2: accuracy is  0.2688\n",
      "iter=10: 65319.8203125, (best_iter=10: 65319.8203125)\n",
      "iter=20: 65047.5703125, (best_iter=20: 65047.5703125)\n",
      "iter=30: 64895.73046875, (best_iter=30: 64895.73046875)\n",
      "iter=40: 64809.140625, (best_iter=40: 64809.140625)\n",
      "iter=50: 64742.078125, (best_iter=50: 64742.078125)\n",
      "iter=60: 64683.06640625, (best_iter=60: 64683.06640625)\n",
      "iter=70: 64647.53515625, (best_iter=70: 64647.53515625)\n",
      "iter=80: 64615.47265625, (best_iter=80: 64615.47265625)\n",
      "iter=90: 64584.7265625, (best_iter=90: 64584.7265625)\n",
      "iter=100: 64554.04296875, (best_iter=100: 64554.04296875)\n",
      "iter=110: 64528.83984375, (best_iter=110: 64528.83984375)\n",
      "iter=120: 64505.3203125, (best_iter=120: 64505.3203125)\n",
      "iter=130: 64483.703125, (best_iter=130: 64483.703125)\n",
      "iter=140: 64463.59375, (best_iter=140: 64463.59375)\n",
      "iter=150: 64446.08203125, (best_iter=150: 64446.08203125)\n",
      "iter=160: 64429.75, (best_iter=160: 64429.75)\n",
      "iter=170: 64415.51953125, (best_iter=170: 64415.51953125)\n",
      "iter=180: 64403.03125, (best_iter=180: 64403.03125)\n",
      "iter=190: 64386.13671875, (best_iter=190: 64386.13671875)\n",
      "iter=200: 64374.6171875, (best_iter=200: 64374.6171875)\n",
      "iter=210: 64359.39453125, (best_iter=210: 64359.39453125)\n",
      "iter=220: 64348.04296875, (best_iter=220: 64348.04296875)\n",
      "iter=230: 64337.86328125, (best_iter=230: 64337.86328125)\n",
      "iter=240: 64328.2421875, (best_iter=240: 64328.2421875)\n",
      "iter=250: 64318.41015625, (best_iter=250: 64318.41015625)\n",
      "iter=260: 64308.88671875, (best_iter=260: 64308.88671875)\n",
      "iter=270: 64296.18359375, (best_iter=270: 64296.18359375)\n",
      "iter=280: 64287.25, (best_iter=280: 64287.25)\n",
      "iter=290: 64278.515625, (best_iter=290: 64278.515625)\n",
      "iter=300: 64270.359375, (best_iter=300: 64270.359375)\n",
      "iter=310: 64261.92578125, (best_iter=310: 64261.92578125)\n",
      "iter=320: 64251.4609375, (best_iter=320: 64251.4609375)\n",
      "iter=330: 64244.93359375, (best_iter=330: 64244.93359375)\n",
      "iter=340: 64236.81640625, (best_iter=340: 64236.81640625)\n",
      "iter=350: 64229.1484375, (best_iter=350: 64229.1484375)\n",
      "iter=360: 64221.734375, (best_iter=360: 64221.734375)\n",
      "iter=370: 64216.9140625, (best_iter=370: 64216.9140625)\n",
      "iter=380: 64210.05859375, (best_iter=380: 64210.05859375)\n",
      "iter=390: 64201.2734375, (best_iter=390: 64201.2734375)\n",
      "iter=400: 64196.93359375, (best_iter=400: 64196.93359375)\n",
      "iter=410: 64191.84765625, (best_iter=410: 64191.84765625)\n",
      "iter=420: 64186.05859375, (best_iter=420: 64186.05859375)\n",
      "iter=430: 64181.66796875, (best_iter=430: 64181.66796875)\n",
      "iter=440: 64176.0859375, (best_iter=440: 64176.0859375)\n",
      "iter=450: 64173.359375, (best_iter=450: 64173.359375)\n",
      "iter=460: 64165.71484375, (best_iter=460: 64165.71484375)\n",
      "iter=470: 64159.3125, (best_iter=470: 64159.3125)\n",
      "iter=480: 64156.046875, (best_iter=480: 64156.046875)\n",
      "iter=490: 64151.2421875, (best_iter=490: 64151.2421875)\n",
      "iter=500: 64147.703125, (best_iter=500: 64147.703125)\n",
      "iter=510: 64145.16015625, (best_iter=510: 64145.16015625)\n",
      "iter=520: 64138.34375, (best_iter=520: 64138.34375)\n",
      "iter=530: 64133.7578125, (best_iter=530: 64133.7578125)\n",
      "iter=540: 64131.7734375, (best_iter=540: 64131.7734375)\n",
      "iter=550: 64129.25, (best_iter=550: 64129.25)\n",
      "iter=560: 64125.7890625, (best_iter=560: 64125.7890625)\n",
      "iter=570: 64119.65625, (best_iter=570: 64119.65625)\n",
      "iter=580: 64115.2890625, (best_iter=580: 64115.2890625)\n",
      "iter=590: 64112.19140625, (best_iter=590: 64112.19140625)\n",
      "iter=600: 64108.5390625, (best_iter=600: 64108.5390625)\n",
      "iter=610: 64105.65625, (best_iter=610: 64105.65625)\n",
      "iter=620: 64102.8515625, (best_iter=620: 64102.8515625)\n",
      "iter=630: 64102.04296875, (best_iter=630: 64102.04296875)\n",
      "iter=640: 64100.50390625, (best_iter=640: 64100.50390625)\n",
      "iter=650: 64097.54296875, (best_iter=650: 64097.54296875)\n",
      "iter=660: 64094.12890625, (best_iter=660: 64094.12890625)\n",
      "iter=670: 64091.8671875, (best_iter=670: 64091.8671875)\n",
      "iter=680: 64086.00390625, (best_iter=680: 64086.00390625)\n",
      "iter=690: 64081.7890625, (best_iter=690: 64081.7890625)\n",
      "iter=700: 64080.26953125, (best_iter=700: 64080.26953125)\n",
      "iter=710: 64076.84375, (best_iter=710: 64076.84375)\n",
      "iter=720: 64076.61328125, (best_iter=720: 64076.61328125)\n",
      "iter=730: 64075.8046875, (best_iter=730: 64075.8046875)\n",
      "iter=740: 64075.5703125, (best_iter=740: 64075.5703125)\n",
      "iter=750: 64073.9765625, (best_iter=750: 64073.9765625)\n",
      "iter=760: 64069.265625, (best_iter=760: 64069.265625)\n",
      "iter=770: 64065.76171875, (best_iter=770: 64065.76171875)\n",
      "iter=780: 64064.5234375, (best_iter=780: 64064.5234375)\n",
      "iter=790: 64064.1875, (best_iter=790: 64064.1875)\n",
      "iter=800: 64063.671875, (best_iter=800: 64063.671875)\n",
      "iter=810: 64061.3359375, (best_iter=810: 64061.3359375)\n",
      "iter=820: 64060.6640625, (best_iter=820: 64060.6640625)\n",
      "iter=830: 64060.27734375, (best_iter=830: 64060.27734375)\n",
      "iter=840: 64058.42578125, (best_iter=840: 64058.42578125)\n",
      "iter=850: 64053.3359375, (best_iter=850: 64053.3359375)\n",
      "iter=860: 64051.6484375, (best_iter=860: 64051.6484375)\n",
      "iter=870: 64051.45703125, (best_iter=867: 64051.45703125)\n",
      "iter=880: 64051.08984375, (best_iter=880: 64051.08984375)\n",
      "iter=890: 64050.9296875, (best_iter=889: 64050.9296875)\n",
      "iter=900: 64050.63671875, (best_iter=900: 64050.63671875)\n",
      "iter=910: 64049.609375, (best_iter=910: 64049.609375)\n",
      "iter=920: 64048.0546875, (best_iter=920: 64048.0546875)\n",
      "iter=930: 64045.01171875, (best_iter=929: 64045.01171875)\n",
      "iter=940: 64043.1484375, (best_iter=940: 64043.1484375)\n",
      "iter=950: 64042.6015625, (best_iter=950: 64042.6015625)\n",
      "iter=960: 64042.36328125, (best_iter=960: 64042.36328125)\n",
      "iter=970: 64040.60546875, (best_iter=970: 64040.60546875)\n",
      "iter=980: 64040.0625, (best_iter=980: 64040.0625)\n",
      "iter=990: 64039.890625, (best_iter=989: 64039.890625)\n",
      "iter=1000: 64039.4921875, (best_iter=1000: 64039.4921875)\n",
      "epoch 3: client-1 3.7310527606166604\n",
      "epoch 3: client-2 3.9403414390959695\n",
      "epoch 3: accuracy is  0.2687\n",
      "iter=10: 65252.9453125, (best_iter=10: 65252.9453125)\n",
      "iter=20: 65002.95703125, (best_iter=20: 65002.95703125)\n",
      "iter=30: 64853.53515625, (best_iter=30: 64853.53515625)\n",
      "iter=40: 64853.53125, (best_iter=31: 64853.53125)\n",
      "iter=50: 64853.53515625, (best_iter=31: 64853.53125)\n",
      "iter=60: 64853.53515625, (best_iter=31: 64853.53125)\n",
      "iter=70: 64853.53125, (best_iter=31: 64853.53125)\n",
      "iter=80: 64853.53515625, (best_iter=31: 64853.53125)\n",
      "iter=82: loss did not improve in the last 50 rounds.\n",
      "epoch 4: client-1 3.6386653301789678\n",
      "epoch 4: client-2 3.9482572260496283\n",
      "epoch 4: accuracy is  0.2698\n",
      "iter=10: 66092.7265625, (best_iter=10: 66092.7265625)\n",
      "iter=20: 65701.625, (best_iter=20: 65701.625)\n",
      "iter=30: 65485.95703125, (best_iter=30: 65485.95703125)\n",
      "iter=40: 65336.72265625, (best_iter=40: 65336.72265625)\n",
      "iter=50: 65237.875, (best_iter=50: 65237.875)\n",
      "iter=60: 65123.8671875, (best_iter=60: 65123.8671875)\n",
      "iter=70: 65064.7578125, (best_iter=70: 65064.7578125)\n",
      "iter=80: 65008.875, (best_iter=80: 65008.875)\n",
      "iter=90: 64954.109375, (best_iter=90: 64954.109375)\n",
      "iter=100: 64905.7265625, (best_iter=100: 64905.7265625)\n",
      "iter=110: 64861.359375, (best_iter=110: 64861.359375)\n",
      "iter=120: 64838.83203125, (best_iter=120: 64838.83203125)\n",
      "iter=130: 64811.7734375, (best_iter=130: 64811.7734375)\n",
      "iter=140: 64789.40625, (best_iter=140: 64789.40625)\n",
      "iter=150: 64765.8125, (best_iter=150: 64765.8125)\n",
      "iter=160: 64740.08203125, (best_iter=160: 64740.08203125)\n",
      "iter=170: 64721.96875, (best_iter=170: 64721.96875)\n",
      "iter=180: 64710.87109375, (best_iter=180: 64710.87109375)\n",
      "iter=190: 64691.734375, (best_iter=190: 64691.734375)\n",
      "iter=200: 64669.0390625, (best_iter=200: 64669.0390625)\n",
      "iter=210: 64664.66015625, (best_iter=210: 64664.66015625)\n",
      "iter=220: 64648.67578125, (best_iter=220: 64648.67578125)\n",
      "iter=230: 64642.98046875, (best_iter=230: 64642.98046875)\n",
      "iter=240: 64634.05859375, (best_iter=240: 64634.05859375)\n",
      "iter=250: 64622.75, (best_iter=250: 64622.75)\n",
      "iter=260: 64617.09765625, (best_iter=260: 64617.09765625)\n",
      "iter=270: 64608.31640625, (best_iter=270: 64608.31640625)\n",
      "iter=280: 64602.3828125, (best_iter=280: 64602.3828125)\n",
      "iter=290: 64595.7109375, (best_iter=290: 64595.7109375)\n",
      "iter=300: 64586.44140625, (best_iter=300: 64586.44140625)\n",
      "iter=310: 64584.546875, (best_iter=310: 64584.546875)\n",
      "iter=320: 64574.98046875, (best_iter=320: 64574.98046875)\n",
      "iter=330: 64569.5390625, (best_iter=330: 64569.5390625)\n",
      "iter=340: 64564.3203125, (best_iter=340: 64564.3203125)\n",
      "iter=350: 64560.62890625, (best_iter=350: 64560.62890625)\n",
      "iter=360: 64552.671875, (best_iter=360: 64552.671875)\n",
      "iter=370: 64549.06640625, (best_iter=370: 64549.06640625)\n",
      "iter=380: 64547.3359375, (best_iter=380: 64547.3359375)\n",
      "iter=390: 64544.91796875, (best_iter=390: 64544.91796875)\n",
      "iter=400: 64540.5546875, (best_iter=400: 64540.5546875)\n",
      "iter=410: 64532.953125, (best_iter=410: 64532.953125)\n",
      "iter=420: 64528.3828125, (best_iter=420: 64528.3828125)\n",
      "iter=430: 64521.8203125, (best_iter=430: 64521.8203125)\n",
      "iter=440: 64517.36328125, (best_iter=440: 64517.36328125)\n",
      "iter=450: 64510.62109375, (best_iter=450: 64510.62109375)\n",
      "iter=460: 64504.55078125, (best_iter=460: 64504.55078125)\n",
      "iter=470: 64501.28125, (best_iter=470: 64501.28125)\n",
      "iter=480: 64496.14453125, (best_iter=480: 64496.14453125)\n",
      "iter=490: 64488.6796875, (best_iter=490: 64488.6796875)\n",
      "iter=500: 64484.27734375, (best_iter=500: 64484.27734375)\n",
      "iter=510: 64479.31640625, (best_iter=510: 64479.31640625)\n",
      "iter=520: 64476.75390625, (best_iter=520: 64476.75390625)\n",
      "iter=530: 64471.45703125, (best_iter=529: 64471.45703125)\n",
      "iter=540: 64470.4140625, (best_iter=540: 64470.4140625)\n",
      "iter=550: 64465.51171875, (best_iter=550: 64465.51171875)\n",
      "iter=560: 64458.60546875, (best_iter=560: 64458.60546875)\n",
      "iter=570: 64455.62109375, (best_iter=569: 64455.62109375)\n",
      "iter=580: 64452.90625, (best_iter=580: 64452.90625)\n",
      "iter=590: 64450.3984375, (best_iter=590: 64450.3984375)\n",
      "iter=600: 64446.05859375, (best_iter=600: 64446.05859375)\n",
      "iter=610: 64443.015625, (best_iter=610: 64443.015625)\n",
      "iter=620: 64439.87890625, (best_iter=620: 64439.87890625)\n",
      "iter=630: 64438.70703125, (best_iter=630: 64438.70703125)\n",
      "iter=640: 64437.10546875, (best_iter=640: 64437.10546875)\n",
      "iter=650: 64435.16015625, (best_iter=650: 64435.16015625)\n",
      "iter=660: 64431.23046875, (best_iter=660: 64431.23046875)\n",
      "iter=670: 64427.8515625, (best_iter=670: 64427.8515625)\n",
      "iter=680: 64423.984375, (best_iter=680: 64423.984375)\n",
      "iter=690: 64419.16796875, (best_iter=690: 64419.16796875)\n",
      "iter=700: 64416.08984375, (best_iter=700: 64416.08984375)\n",
      "iter=710: 64414.078125, (best_iter=709: 64414.07421875)\n",
      "iter=720: 64411.34765625, (best_iter=720: 64411.34765625)\n",
      "iter=730: 64408.53515625, (best_iter=730: 64408.53515625)\n",
      "iter=740: 64406.62109375, (best_iter=740: 64406.62109375)\n",
      "iter=750: 64406.0703125, (best_iter=749: 64406.0703125)\n",
      "iter=760: 64404.8046875, (best_iter=760: 64404.8046875)\n",
      "iter=770: 64401.0625, (best_iter=770: 64401.0625)\n",
      "iter=780: 64397.10546875, (best_iter=780: 64397.10546875)\n",
      "iter=790: 64395.80078125, (best_iter=790: 64395.80078125)\n",
      "iter=800: 64395.171875, (best_iter=800: 64395.171875)\n",
      "iter=810: 64393.63671875, (best_iter=810: 64393.63671875)\n",
      "iter=820: 64392.22265625, (best_iter=820: 64392.22265625)\n",
      "iter=830: 64389.53515625, (best_iter=830: 64389.53515625)\n",
      "iter=840: 64388.421875, (best_iter=840: 64388.421875)\n",
      "iter=850: 64386.140625, (best_iter=850: 64386.140625)\n",
      "iter=860: 64385.12109375, (best_iter=860: 64385.12109375)\n",
      "iter=870: 64380.55078125, (best_iter=870: 64380.55078125)\n",
      "iter=880: 64378.58203125, (best_iter=880: 64378.58203125)\n",
      "iter=890: 64374.00390625, (best_iter=890: 64374.00390625)\n",
      "iter=900: 64372.91796875, (best_iter=900: 64372.91796875)\n",
      "iter=910: 64370.87109375, (best_iter=910: 64370.87109375)\n",
      "iter=920: 64368.96484375, (best_iter=920: 64368.96484375)\n",
      "iter=930: 64367.578125, (best_iter=930: 64367.578125)\n",
      "iter=940: 64366.4375, (best_iter=940: 64366.4375)\n",
      "iter=950: 64364.03515625, (best_iter=950: 64364.03515625)\n",
      "iter=960: 64363.046875, (best_iter=959: 64363.046875)\n",
      "iter=970: 64362.7734375, (best_iter=970: 64362.7734375)\n",
      "iter=980: 64362.2734375, (best_iter=980: 64362.2734375)\n",
      "iter=990: 64359.12109375, (best_iter=990: 64359.12109375)\n",
      "iter=1000: 64357.48046875, (best_iter=1000: 64357.48046875)\n"
     ]
    }
   ],
   "source": [
    "from aijack.attack import GradientInversion_Attack, GradientInversionAttackManager\n",
    "\n",
    "# # DLG Attack (Zhu, Ligeng, Zhijian Liu, and Song Han. \"Deep leakage from gradients.\" Advances in Neural Information Processing Systems 32 (2019).)\n",
    "# dlg_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\")\n",
    "# FedAvgServer_DLG = dlg_manager.attach(FedAvgServer)\n",
    "\n",
    "# # GS Attack (Geiping, Jonas, et al. \"Inverting gradients-how easy is it to break privacy in federated learning?.\" Advances in Neural Information Processing Systems 33 (2020): 16937-16947.)\n",
    "# gs_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"cossim\", tv_reg_coef=0.01)\n",
    "# FedAvgServer_GS = gs_manager.attach(FedAvgServer)\n",
    "\n",
    "# iDLG (Zhao, Bo, Konda Reddy Mopuri, and Hakan Bilen. \"idlg: Improved deep leakage from gradients.\" arXiv preprint arXiv:2001.02610 (2020).)\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "idlg_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\", num_iteration=1000, optimize_label=False, device=device)\n",
    "FedAvgServer_iDLG = idlg_manager.attach(FedAvgServer)\n",
    "\n",
    "# # CPL (Wei, Wenqi, et al. \"A framework for evaluating gradient leakage attacks in federated learning.\" arXiv preprint arXiv:2004.10397 (2020).)\n",
    "# cpl_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\", optimize_label=False, lm_reg_coef=0.01)\n",
    "# FedAvgServer_CPL = cpl_manager.attach(FedAvgServer)\n",
    "\n",
    "# # GradInversion (Yin, Hongxu, et al. \"See through gradients: Image batch recovery via gradinversion.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.)\n",
    "# gi_manager = GradientInversionAttackManager((1, 28, 28), distancename=\"l2\", optimize_label=False, bn_reg_layers=[global_model.body[1], global_model.body[4], global_model.body[7]],\n",
    "#                                     group_num = 5, tv_reg_coef=0.00, l2_reg_coef=0.0001, bn_reg_coef=0.001, gc_reg_coef=0.001)\n",
    "# FedAvgServer_GI = gi_manager.attach(FedAvgServer)\n",
    "\n",
    "server = FedAvgServer_iDLG(clients, global_model, lr=0.02)\n",
    "server.to(device)\n",
    "print(device)\n",
    "# --- normal federated learning --- #\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "        server.parameters(), lr=0.02, weight_decay=1e-7, momentum=0.9\n",
    "    )\n",
    "\n",
    "\n",
    "for epoch in range(5):\n",
    "    for client_idx in range(2):\n",
    "        client = clients[client_idx]\n",
    "        trainloader = trainloaders[client_idx]\n",
    "        optimizer = optimizers[client_idx]\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for _, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = client(inputs)\n",
    "            loss = criterion(outputs, labels.to(torch.int64))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(\n",
    "            f\"epoch {epoch}: client-{client_idx+1}\",\n",
    "            running_loss / dataset_nums[client_idx],\n",
    "        )\n",
    "    server.receive()\n",
    "    server.update()\n",
    "    server.distribtue()\n",
    "\n",
    "    in_preds = []\n",
    "    in_label = []\n",
    "    with torch.no_grad():\n",
    "        for data in global_trainloader:\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = server.server_model(inputs)\n",
    "            in_preds.append(outputs)\n",
    "            in_label.append(labels)\n",
    "        in_preds = torch.cat(in_preds)\n",
    "        in_label = torch.cat(in_label)\n",
    "    print(\n",
    "        f\"epoch {epoch}: accuracy is \",\n",
    "        accuracy_score(\n",
    "            np.array(torch.argmax(in_preds, axis=1).cpu()), np.array(in_label)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    reconstructed_image, reconstructed_label = server.attack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARI0lEQVR4nO3dV4zW9bbG8fWXIr3XAaT3AQHpRVBAEwUbBI+AaBA1opLIlV4gMTlGvFEjaKIQFFGUEBFsiKHHDSIEBGbovUjvdUB4z80++4rfs07gJCzJ95N4w5M1vFOe/bpn+fv9s1wuZwDiueNWvwAA10c5gaAoJxAU5QSCopxAUJQTCIpyAkFRzttElmVLsiy7lGXZuX//s+VWvybcHMp5e3kll8uV+/c/zW/1i8HNoZxAUJTz9vJOlmXHsiz7V5ZlfW71i8HNyfhva28PWZZ1MbONZnbZzP7LzCaZWbtcLrfjlr4w3DDKeZvKsuwXM/spl8tNvNWvBTeGf629feXMLLvVLwI3jnLeBrIsq5Rl2YNZlpXKsqx4lmXDzOxeM/vlVr823Ljit/oF4P9FCTP7bzNrYWZXzWyzmT2Wy+W23tJXhZvC/+cEguJfa4GgKCcQFOUEgqKcQFDyt7UPPvig/G3R6NGj5QffujX9y8Jt27bJ2Q0bNsj8vvvuk3mxYsWSWf/+/eXsZ599JvO+ffvKfOrUqTKfMWNGMnvvvffk7Nq1a2Xeu3dvmZcuXVrm7du3T2affvqpnL127ZrMve/Z5cuXk9nVq1fl7OnTp2VeVFQk8/z8fJnv3Lkzme3evVvOHjx4UObz5s277j6ad04gKMoJBEU5gaAoJxAU5QSCopxAUJQTCEr+h+9jxoyRe86yZcvKD16+fPlkdu7cOTnr7RI//PBDmbdu3fqG/+5mzZrJ/Oeff5a5t/9Ve7HZs2fL2TVr1sh8ypQpMl+5cqXMlVOnTsn85Zdflvn+/ftlvnr16mRWWFgoZ6tXry7zwYMHy1ztMc3Mvvzyy2Q2YsQIObto0SLvY7PnBP5JKCcQFOUEgqKcQFCUEwiKcgJBUU4gKHmec8WKFXL4rbfekvnixYuT2ZEjR+Ts8uXLZa52qGZmrVq1SmYTJ+p7losX15cSevvd9evXy1ztOb0d6bRp02ReoUIFma9bt07maj989uxZOav2lGZmCxYskHnbtm2Tmfc1z8vLk/m+fftkXqNGDZmrs6hHjx6VsyVLlpR5Cu+cQFCUEwiKcgJBUU4gKMoJBEU5gaDkzmDs2LFy+NChQzJXx3yqVq0qZ8+cOSNz73iSukJy6NChcrZevXoyL1GihMyPHTsmc3VkrVy5cnK2fv36MveOPjVo0EDmffr0SWbetZqbNm2S+a+//irzAQMGJLO77rpLzqrrRs38z9vTs2fPZLZ582Y5662gUnjnBIKinEBQlBMIinICQVFOICjKCQRFOYGg5J5z/vz5cvjNN9+U+Z9//pnMLly4IGdr164tc+9qTLWrzLLr3kT4H96xK+9ImHr8oJnZ0qVLk5l3xaO3M7vjDv2/t97+uE6dOsns448/vuFZM70rNNNH9bwd6ZNPPilz73vu7YfVLrNdu3ZydtWqVTJP4Z0TCIpyAkFRTiAoygkERTmBoCgnEBTlBIKSe878/Hw57F0J2K1bt2Tm7QqvXLkic+9soboa8/Dhw3LWO69ZUFAg82eeeUbm6qpE75zr8OHDZe5dKfr888/L/Keffkpmw4YNk7N79+6Vea9evW4qV5YsWSLzhg0byrxWrVoyV9e8duzYUc6OGzdO5im8cwJBUU4gKMoJBEU5gaAoJxAU5QSCopxAUHLPOWvWLDl86dIlme/YsSOZderUSc5697eqe2nN9C7SO1e4detWmXt7LW8Hq3jnMadOnSpz7yxply5dZF5UVJTMJk2aJGcHDhwo8zlz5shcPSLQ2//u2bNH5uPHj5f5vHnzZK5+Xn/77Tc526JFC5l37979un/OOycQFOUEgqKcQFCUEwiKcgJBUU4gqCyXyyXDxYsXp0MzmzlzpvzgNWrUSGbXrl2Ts94qRV2jaGa2ZcuWZNahQwc56/1a3luleFeK9uvXL5mdP39eznqrFm+9pY7xmZl98sknySwvL0/O/vHHHzJv3LixzNV1qGrFY2ZWvnx5mR84cEDmV69elXnXrl2T2ZQpU+Rs5cqVZT5z5szr3tvJOycQFOUEgqKcQFCUEwiKcgJBUU4gKMoJBCWXhW+//bYcHjt2rMyPHTuWzH788Uc5W7duXZl7R5/atGmTzA4dOiRnvccTeo90U7tjM7N9+/YlM+/Il5o1878u3iMA1b5v48aNcrZ169Yy79+/v8zVIyO9azOnT58u8+bNm8vce7RikyZNktno0aPl7LJly2SewjsnEBTlBIKinEBQlBMIinICQVFOICjKCQQl95yjRo2Sw94ZuHPnziWzatWqydkePXrIXJ0VNTObPHmyzJX27dvLfNu2bTJ/6qmnZL569epk5p1j9fZx3ms7fvy4zDt37pzMLl68KGe9nwfvsY5ql6i+Zmb+I/68xzp650HVz/LKlSvlbNu2bWWewjsnEBTlBIKinEBQlBMIinICQVFOICjKCQQl95xLliyRw1l23es2/6NChQrJTO20zMwWLlwoc3Ve00zfgdq0aVM5653nrFmzpsy9vZc6k1mvXj05e7P32nqfW8uWLZPZ3Llz5ay3u965c6fM169fn8xOnTolZ4cMGSJz9fNg5p9V/eKLL5JZs2bN5GyjRo1knsI7JxAU5QSCopxAUJQTCIpyAkFRTiAoygkEJfecrVq1ksO//PKLzB955JFk5p1bLFOmjMz3798v8zp16iSzmzmHaqbv4zXTu0IzvXPzPu/t27fLXJ3HNDObOHGizFu0aJHMvGd/envMwsJCmavnpqqduZl/l7D383bnnXfKvHv37smsoKBAzno/bym8cwJBUU4gKMoJBEU5gaAoJxAU5QSCkquUKlWqyOHnnntO5gsWLEhm3vWR48ePl/mgQYNkfvny5WR24sQJOetdZeh9Xbx1h3q84YEDB+Ss99p+//13mXuPP7z//vuTmbe+8tYdf//9t8x37NiRzLwrPb1HRubl5cncu3pz4MCBycz7vLyvWwrvnEBQlBMIinICQVFOICjKCQRFOYGgKCcQVJbL5ZLhE088kQ5NHwkzMysqKkpmFStWlLOVK1eWubpG0Uxf2+nttNTXxMysT58+Mveup1Qf/9q1a3LWu1LU23N6x5cqVaqUzO655x45u3z5cpk//vjjMj98+HAy++uvv+Ts1q1bZe7tpr3HG1avXj2ZeUcIvf3vCy+8cN0fVt45gaAoJxAU5QSCopxAUJQTCIpyAkFRTiAoeZ6zVq1acvjMmTMy3717dzLzHhfnnZHzdonqzObw4cPl7IYNG2S+bt06masrHs3MTp8+nczUOVQzs6+++krmah9nZtauXTuZq0cMemds69evL/Ovv/5a5mpf2Lt3bzm7a9cumXfr1k3masdqpn/WvfPBjRs3lnkK75xAUJQTCIpyAkFRTiAoygkERTmBoCgnEJTccw4YMEAOr1mzRuZqN+Q9cs173Jw337Vr12SWn58vZ/ft2yfzXr16yXzatGkyf+WVV5KZt2MdN26czJcuXSrznj17ylztMvv27StnS5QoIXPv0YrqvOjUqVPlrPp+m/lnLr3dtZpv06aNnG3atKnMU3jnBIKinEBQlBMIinICQVFOICjKCQRFOYGg5L21Y8aMkRe4Pvroo/KDL1y4MJmVK1dOznrnNb17bdWZSe9jX7lyRebeDrZRo0YyVzsz7zmU3n293i5SPWfSTN89u2nTJjl7s/f9lixZMplt3LhRzhYUFMi8ZcuWMi9btqzM1c9rgwYN5OySJUtk/vrrr3NvLfBPQjmBoCgnEBTlBIKinEBQlBMISh4ZGzlypBx+5513ZN6+fftk5v362XuUnXcNo3dVonLy5EmZHz16VObe53bhwoVkdurUKTnbqVMnmaurLc38NZI65uetiAoLC2XuraDUyqF06dJytnXr1jL3jhiWKlVK5urqzGXLlslZ73uWwjsnEBTlBIKinEBQlBMIinICQVFOICjKCQQl95xz5syRw97xI7WrbNiwoZzdvn27zIcNGyZzdWRs586dcnbw4MEyX7lypcy9Y195eXnJzPu6VKhQQebe9+zzzz+/4Y/vXT958OBBmRcVFclcPf7QezSi+pqa+Y+U9Fy8eDGZNWnSRM6WKVPmhv5O3jmBoCgnEBTlBIKinEBQlBMIinICQVFOICh5Nearr74q7zr0Hn127dq1ZKauYDTzz2t6uyP1ODm1szLzH6O3ePFimT/wwAMyHzJkSDI7cOCAnPXyl156SeYTJ06UuXqso7en9K6f9Ha06sxm8eJyJe9eZ+qdwfV2040bN05mdevWlbN79+6V+ZgxY7gaE/gnoZxAUJQTCIpyAkFRTiAoygkERTmBoOTyyNslVqxYUeYbNmxIZqNGjZKzEyZMkPldd90l87NnzyazLl26yNm7775b5t6+bu3atTJ/4403ktmzzz4rZ707cb/99luZe7vKEiVK3PBs7dq1Ze79PKkzl96jD8+dOyfz/v37y9x7fKHaL2/dulXOencRp/DOCQRFOYGgKCcQFOUEgqKcQFCUEwhKrlK8x6qpdYWZftyc92t378iY9zi6Zs2aJbPHHntMzk6ZMkXmmzdvlrl3bGv37t3JTD0Gz8ysXLlyMvcedaeO8ZmZ9ejRI5m1atVKzv7www8yV8f4zPQxwipVqshZb7XmHRnz8o0bNyazQYMGyVnv6swU3jmBoCgnEBTlBIKinEBQlBMIinICQVFOICi55/zoo4/k8NNPPy1zdWRsz549crZDhw4ynz9/vszVPu/dd9+Vs941iX369JG597i5CxcuJLNSpUrJ2SNHjsjc2/d5Ozf12mfPni1nz58/L/N9+/bJXO3FvdftHWfzrmL1dvadO3dOZpUqVZKz3mMZ27Vrd90/550TCIpyAkFRTiAoygkERTmBoCgnEBTlBIKSe85JkybJ4RMnTshc7eRWrFghZ2vUqCHzevXqyXzLli3JrGPHjnLWu8LRuzrzgw8+kHm/fv2SmfdYxQULFsh8xIgRMv/mm29kfvny5WRWvnx5Oet9T7xH5al87ty5crZy5coy965D9T43dSWp93l7V2em8M4JBEU5gaAoJxAU5QSCopxAUJQTCIpyAkHJPeeuXbvk8KxZs2Su7lC999575ezJkydl7t1re/Xq1WTm3d3qnc+bPn26zL0zmYWFhcnMe5Td0qVLZa4e4Wfm7wPVvbjFi8sfF/vuu+9k/tprr8lcPWbv9OnTctb7mi9atEjm3mMd1f75+++/l7PefjeFd04gKMoJBEU5gaAoJxAU5QSCopxAUJQTCCrL5XLJcNWqVenQ9DMLzfR5T3Wn7f9F6q7P/6V2md6ZRu+8Zq9evW747zbT5/u8PaR3N2zTpk1lvnLlSpmr/fHQoUPl7Lhx42Tufc/VOVvvvOWLL74o83Xr1snce+aq6on3/fZ2tBMmTMiu9+e8cwJBUU4gKMoJBEU5gaAoJxAU5QSCkmeA3n//fTl87NgxmT/88MPJzDvyVbp0aZlfunRJ5lWqVElmxYoVu+FZM//X7nl5eTJXKybv6JL3CMBDhw7JvGbNmjJXX/eCggI5611n2rBhQ5mrY18VK1aUs94ax/ueN2/eXObq582bnTx5ssxTeOcEgqKcQFCUEwiKcgJBUU4gKMoJBEU5gaDknvOhhx6Sw0ePHpW52i3t2bNHzpYtW1bmHTp0kLm64rFTp05yduTIkTKfOXOmzL1do7pmsVq1anJ2x44dMj9+/LjMGzduLPP8/PxktmrVKjmrvuZmZlWrVpW52pMOHDhQznpH6Zo1ayZz7+dpxowZyexmHh+o8M4JBEU5gaAoJxAU5QSCopxAUJQTCIpyAkHJqzEB3Dq8cwJBUU4gKMoJBEU5gaAoJxAU5QSC+h+kDeMdMyae/QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(1, 1, 1)\n",
    "ax1.imshow(reconstructed_image.detach().cpu().numpy()[0][0], cmap=\"gray\")\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title(reconstructed_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bada175b2026446b07b84b06853f477db48be1a8bf5860289690b810278eac7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
